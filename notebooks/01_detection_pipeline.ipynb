{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Campfire Detection Pipeline for Solar Orbiter HRIEUV174 Data\n",
    "The goal of this notebook is to try out different detection algorithms for detecting small campfires in Solar Orbiter's Extreme UV Imager (EUV) data. You'll find\n",
    "- functions implementing detection algorithms\n",
    "- helper functions for handling, storing and visualizing data.\n",
    "\n",
    "In particular, the output includes\n",
    "- single frame showcases of detections and filters\n",
    "- .csv output files from the filtered dataframes\n",
    "- mp4 files with or without the detections from a selected algorithm\n",
    "- event statistics.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, let's import the required modules and set a global root path variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all important libraries\n",
    "from __future__ import annotations\n",
    "from typing import List, Tuple, Dict, Any, Optional, Iterable, TypedDict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import disk, binary_dilation\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import sunpy\n",
    "from sunpy.map import MapSequence\n",
    "import astropy.units as u\n",
    "import pickle\n",
    "from sunpy.visualization.colormaps import cm\n",
    "import imageio.v2 as imageio\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# helpful aliases\n",
    "MapSeq = MapSequence\n",
    "BBox = Tuple[int, int, int, int]\n",
    "DetectionDict = Dict[str, Any]\n",
    "DetectionRow = pd.Series\n",
    "DetectionFrame = pd.DataFrame\n",
    "\n",
    "# make typed dictionary for type hinting\n",
    "class CampfireData(TypedDict):\n",
    "    frame: int\n",
    "    x: float\n",
    "    y: float\n",
    "    area_px: int\n",
    "    area_Mm2: float\n",
    "    intensity: float\n",
    "    bbox: BBox\n",
    "\n",
    "# GLOBAL VARIABLE: ROOT PATH\n",
    "root_dir = Path().resolve().parents[0]\n",
    "print(f\"Root directory: {root_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "- **load_dataset():** Loads the specified dataset (from pickle cache if possible) and saves the sequence in a variable.\n",
    "- **save_to_csv():** Saves a data frame to a .csv file in the ../results/csv folder with the specified name.\n",
    "- **showcase_detections():** Showcases the detections from a specified algorithm on a specified frame using bboxes to overlay on top of the detections.\n",
    "- **make_movie():** Renders all frames from the sequence at a specified framerate, with or without detections, and saves the file in \"../results/video\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset: str) -> MapSeq:\n",
    "    \"\"\" \n",
    "    Loads the specified data set (from a pickle cache if possible) and saves the sunpy MapSequence in a variable.\n",
    "    \"\"\"\n",
    "    raw_dir = root_dir / \"data\" / \"raw\" / f\"{dataset}\"\n",
    "    processed_dir = root_dir / \"data\" / \"processed\"\n",
    "    processed_dir.mkdir(parents=True, exist_ok=True) # make directory if it doesn't exist already\n",
    "    cache_file = processed_dir / f\"{dataset}_sequence.pkl\"\n",
    "\n",
    "    # load or render sequence if necessary\n",
    "    if cache_file.exists():\n",
    "        sequence = pickle.load(open(cache_file, \"rb\")) # binary read mode\n",
    "        print(f\"Cached sequence loaded ({len(sequence)} maps)\")\n",
    "    else:\n",
    "        files = sorted(glob.glob(str(raw_dir / \"*.fits\")))\n",
    "        sequence = sunpy.map.Map(files, sequence=True)\n",
    "        pickle.dump(sequence, open(cache_file, \"wb\")) # binary write mode\n",
    "        print(f\"First load --> saved cache ({len(sequence)} maps)\")\n",
    "    return sequence\n",
    "    \n",
    "#=================================================================================================================================================\n",
    "\n",
    "def save_to_csv(df: pd.DataFrame, file_name: str) -> None:\n",
    "    results_dir = root_dir / \"results\" / \"csv\"\n",
    "    results_dir.mkdir(parents = True, exist_ok = True) # make the directory if it doesn't exist already, otherwise do nothing\n",
    "    \n",
    "    file_path = results_dir / f\"detections_{file_name}.csv\"\n",
    "\n",
    "    df.to_csv(file_path, index = False) # no need for indices inside .csv file\n",
    "    print(f\"Saved {len(df)} detections to: {file_path}\")\n",
    "\n",
    "#=================================================================================================================================================\n",
    "def showcase_detections(sequence: MapSeq, \n",
    "                        sample_frame: int, \n",
    "                        df: pd.DataFrame, \n",
    "                        factor: float = 10.0,\n",
    "                        vmin_pct: float = 0.05,\n",
    "                        vmax_pct: float = 99.5,\n",
    "                        dpi: int = 200,) -> None: \n",
    "    \"\"\" \n",
    "    Displays a sample frame from the map sequence with bounding boxes (scaled by \"factor\" for visibility) over the detections from a dataframe.\n",
    "    \"\"\"\n",
    "\n",
    "    # create plot\n",
    "    cmap = cm.cmlist[\"solar orbiterhri_euv174\"]\n",
    "    m = sequence[sample_frame]\n",
    "    data = m.data.flatten()\n",
    "    plt.figure(figsize=(6, 6), dpi = dpi)\n",
    "\n",
    "    # improve contrast\n",
    "    vmin = np.percentile(data, vmin_pct)\n",
    "    vmax = np.percentile(data, vmax_pct)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12,7), dpi = dpi, gridspec_kw={'wspace': 0.05})\n",
    "    data = m.data\n",
    "\n",
    "    # original frame\n",
    "    ax[0].imshow(data, cmap = cmap, vmin = vmin, vmax = vmax, origin = \"lower\")\n",
    "    ax[0].set_title(f\"Original Frame {sample_frame}\")\n",
    "    ax[0].axis(\"off\")\n",
    "\n",
    "    # detections\n",
    "    ax[1].imshow(data, cmap = cmap, vmin = vmin, vmax = vmax, origin = \"lower\")\n",
    "    ax[1].set_title(f\"Detections in Frame {sample_frame}\")\n",
    "    ax[1].axis(\"off\")\n",
    "\n",
    "    plt.suptitle(f\"Solar Orbiter / EUI HRI-EUV-174\\n{sequence[sample_frame].date.isot}\", color = \"black\", fontsize = 14, y=0.9)\n",
    "\n",
    "    # add detections with bboxes\n",
    "    detections = df[df[\"frame\"] == sample_frame]\n",
    "\n",
    "    for _, row in detections.iterrows():\n",
    "        centroid_x = row[\"x\"]\n",
    "        centroid_y = row[\"y\"]\n",
    "\n",
    "        min_row, min_col, max_row, max_col = row[\"bbox\"] \n",
    "        width = max_col - min_col\n",
    "        height = max_row - min_row\n",
    "        area = width * height\n",
    "\n",
    "        # scale the boxes for better visibility of detections\n",
    "        if area <= 3: \n",
    "            scalar = factor * 4\n",
    "        elif 3 < area <= 20:\n",
    "            scalar = factor * 2\n",
    "        elif 20 < area <= 40:\n",
    "            scalar = factor\n",
    "        elif 40 < area <= 60:\n",
    "            scalar = factor * 0.8\n",
    "        else: \n",
    "            scalar = factor * 0.45\n",
    "                    \n",
    "        width *= scalar\n",
    "        height *= scalar\n",
    "\n",
    "        # compute bottom left corner so centroid is in the center\n",
    "        bottom_left_x = centroid_x - (width / 2)\n",
    "        bottom_left_y = centroid_y - (height / 2)\n",
    "\n",
    "        bbox = patches.Rectangle(\n",
    "            (bottom_left_x, bottom_left_y),\n",
    "            width, height,\n",
    "            facecolor = \"none\",\n",
    "            edgecolor = \"lightblue\",\n",
    "            linewidth = 1\n",
    "        )\n",
    "        ax[1].add_patch(bbox) # gca = get current axes\n",
    "        \n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "#=================================================================================================================================================\n",
    "\n",
    "def make_movie(sequence: MapSeq, \n",
    "               df: Optional[pd.DataFrame] = None, \n",
    "               file_name: str = \"movie\", \n",
    "               fps: int = 10, \n",
    "               factor: float = 10, \n",
    "               show_detections: bool = False, \n",
    "               vmin_pct: float = 0.01, \n",
    "               vmax_pct: float = 99.99, \n",
    "               use_global_clipping: bool = False) -> None:\n",
    "    \"\"\" \n",
    "    Renders a .mp4 files of the map sequence, with or without scaled bounding boxes over the detections.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sequence: sunpy.map.MapSequence\n",
    "        Input data sequence. \n",
    "    df: Optional[pd.DataFrame] = None\n",
    "        Dataframe with the detections to be displayed, if desired.\n",
    "    file_name: str\n",
    "        File name (automatically generated from parameters by default).\n",
    "    fps: int, default 10\n",
    "        Frames per second for the movie.\n",
    "    factor: float, default 10.0\n",
    "        Scales the bounding boxes of detections by a factor for better visibility.\n",
    "    show_detections: bool, default False\n",
    "        Just renders the map sequence without bboxes if show_detections == False.\n",
    "    vmin_pct, vmax_pct: float\n",
    "        Percentage defining the data range the colormap covers. Smaller range = higher contrast.\n",
    "    use_global_clipping: bool, default False\n",
    "        True: Determines vmin and vmax from around 50 sample frames and uses those values globally.\n",
    "        False: Calculates vmin and vmax for each frame individually.\n",
    "    Returns\n",
    "    -------\n",
    "    .mp4 file in the specified results folder.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # show length of input sequence\n",
    "    print(f\"Using {len(sequence)} frames for video.\")\n",
    "\n",
    "    # Set up paths\n",
    "    output_file = root_dir / \"results\" / \"video\" / f\"{file_name}.mp4\"\n",
    "    output_file.parent.mkdir(parents = True, exist_ok = True)\n",
    "    \n",
    "    # colormap\n",
    "    cmap = cm.cmlist[\"solar orbiterhri_euv174\"] # other options: check https://docs.sunpy.org/en/stable/reference/visualization.html\n",
    "\n",
    "    if show_detections:\n",
    "        print(f\"Visualizing {len(df)} total detections with {factor}x scaled, centered bounding boxes.\")\n",
    "\n",
    "    # Global Clipping Filter\n",
    "    if use_global_clipping:\n",
    "        sample = [m.data.flatten() for m in sequence[::max(1, len(sequence)//50)]]\n",
    "        all_samples = np.concatenate(sample)\n",
    "        vmin = np.percentile(all_samples, vmin_pct)\n",
    "        vmax = np.percentile(all_samples, vmax_pct)\n",
    "        print(f\"Global scaling: vmin={vmin:.1f}, vmax={vmax:.1f}\")\n",
    "    else:\n",
    "        vmin = vmax = None # will be computed per frame later\n",
    "    \n",
    "\n",
    "    # H.264 Encoder + YUV 4:2:0 color space with planar layout\n",
    "    with imageio.get_writer(output_file, fps=fps, codec=\"libx264\", pixelformat=\"yuv420p\") as writer:\n",
    "        for idx, m in enumerate(sequence):\n",
    "            data = m.data # extract 2D image np.array with pixel intensities\n",
    "            detections = df[df[\"frame\"] == idx]\n",
    "\n",
    "            if not use_global_clipping:\n",
    "                vmin, vmax = np.percentile(data, (vmin_pct, vmax_pct))\n",
    "\n",
    "            fig = plt.figure(figsize = (8, 8), facecolor = \"black\", dpi = 200) # black background\n",
    "            ax = plt.subplot()\n",
    "            ax.imshow(data, cmap = cmap, vmin = vmin, vmax = vmax, origin = \"lower\") # origin: .fits have origin at lower left corner\n",
    "            ax.set_title(f\"Solar Orbiter / EUI HRI_EUV_174\\n{m.date.isot}\", color = \"white\", fontsize = 12)\n",
    "            ax.set_axis_off()\n",
    "\n",
    "            if show_detections and df is not None:\n",
    "                # Draw scaled and centered bboxes\n",
    "                for _, row in detections.iterrows():\n",
    "                    centroid_x = row[\"x\"]\n",
    "                    centroid_y = row[\"y\"]\n",
    "\n",
    "                    min_row, min_col, max_row, max_col = row[\"bbox\"] \n",
    "                    width = max_col - min_col\n",
    "                    height = max_row - min_row\n",
    "                    area = width * height\n",
    "\n",
    "                    # scale the boxes for better visibility of detections\n",
    "                    if area <= 3: \n",
    "                        scalar = factor * 4\n",
    "                    elif 3 < area <= 20:\n",
    "                        scalar = factor * 2\n",
    "                    elif 20 < area <= 40:\n",
    "                        scalar = factor\n",
    "                    elif 40 < area <= 60:\n",
    "                        scalar = factor * 0.8\n",
    "                    else: \n",
    "                        scalar = factor * 0.45\n",
    "                        \n",
    "                    width *= scalar\n",
    "                    height *= scalar\n",
    "\n",
    "                    # compute bottom left corner so centroid is in the center\n",
    "                    bottom_left_x = centroid_x - (width / 2)\n",
    "                    bottom_left_y = centroid_y - (height / 2)\n",
    "\n",
    "                    bbox = patches.Rectangle(\n",
    "                        (bottom_left_x, bottom_left_y),\n",
    "                        width, height,\n",
    "                        facecolor = \"none\",\n",
    "                        edgecolor = \"lightblue\",\n",
    "                        linewidth = 2\n",
    "                    )\n",
    "                    ax.add_patch(bbox)\n",
    "\n",
    "            plt.tight_layout(pad = 0.5)\n",
    "\n",
    "            # force matplotlib to render the figure into a buffer in memory\n",
    "            fig.canvas.draw() \n",
    "\n",
    "            # buffer_rgba() returns [width x height x (R, G, B, A)] --> [:, :, :3] --> drop alpha (not needed with imageio)\n",
    "            frame = np.array(fig.canvas.renderer.buffer_rgba())[:, :, :3]\n",
    "            writer.append_data(frame)\n",
    "\n",
    "            plt.close(fig) # free memory (!)\n",
    "            print(f\"Frame {idx + 1} / {len(sequence)} rendered...\", end = \"\\r\")\n",
    "            \n",
    "    print(f\"\\nDone! Movie saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Detection Algorithms\n",
    "\n",
    "##### The next cells contain all the detection functions we can play around with, along with functions to help handle and visualize the produced datasets. In particular, this includes:\n",
    "- **sigma_threshold():** Calculates the mean brightness $\\mu$ and standard deviation $\\sigma$ of all pixels in a frame, then applies a minimum threshold for detection of $\\mu + n\\sigma$ (either per frame or global with ~50 frame average).\n",
    "- **filter_by_area():** Filter detections by minimum and maximum pixel area.\n",
    "- **build_masks(), apply_masks(), visualize_mask():** build_masks() creates per-frame masks covering the brightest x% of pixels, which can be visualized with visualize_mask(). Any events within the mask can be removed from a dataframe with apply_masks().\n",
    "- **build_event_catalog():** Uses scikit.learn's DBSCAN to identify spatiotemporal clusters, filters by lifetime and area, then returns an event catalog (with event statistics) and a per-frame detection data frame for visualization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma_threshold(sequence: MapSeq, sigma: float = 3, per_frame: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Set a baseline for detections using a simple sigma-clipping threshold (mean + x sigma).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sequence : sunpy.map.MapSequence\n",
    "        Input data sequence.\n",
    "    sigma : float, default 3.0\n",
    "        Number of standard deviations above the background.\n",
    "    per_frame : bool, default False\n",
    "        Compute threshold per frame instead of sampling around 50 frames for global values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with one row per detection.\n",
    "    \"\"\"\n",
    "    if not per_frame:\n",
    "        # compute mean and std from at least 50 sample frames \n",
    "        sample = [m.data.astype(float).ravel() for m in sequence[::max(1, len(sequence)//50)]]\n",
    "        all_samples = np.concatenate(sample)\n",
    "        low, high = np.percentile(all_samples, [1, 99]) # remove extreme 1%\n",
    "        clean_samples = all_samples[(all_samples >= low) & (all_samples <= high)]\n",
    "        mean, std = clean_samples.mean(), clean_samples.std()\n",
    "\n",
    "    detections = []\n",
    "    for i, m in enumerate(sequence):\n",
    "        # only a small angle approximation // TODO: implement foreshortening to correct for spherical geometry.\n",
    "        pixel_area_Mm2 = (m.scale.axis1.to(u.rad / u.pixel) * m.scale.axis2.to(u.rad / u.pixel) * m.observer_coordinate.radius.to(u.km)**2).value / 1_000_000\n",
    "        img = m.data.astype(float)\n",
    "        if per_frame:\n",
    "            mean, std = img.mean(), img.std()\n",
    "        mask = img > (mean + (sigma * std))\n",
    "        lab = label(mask)\n",
    "        props = regionprops(lab, intensity_image=img)\n",
    "\n",
    "        for p in props:\n",
    "            detections.append({\n",
    "                \"frame\": i,\n",
    "                \"x\": p.centroid[1],\n",
    "                \"y\": p.centroid[0], # swapped, because (y, x) in .fits format\n",
    "                \"area_px\": p.area,\n",
    "                \"area_Mm2\": p.area * pixel_area_Mm2,\n",
    "                \"intensity\": p.max_intensity,\n",
    "                \"bbox\": p.bbox,\n",
    "            })\n",
    "    df = pd.DataFrame(detections)\n",
    "\n",
    "    if len(df) == 0:\n",
    "        print(\"No detections found.\")\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"{len(df)} detections found.\")\n",
    "        return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_area(df: pd.DataFrame, min_area_px: int =3, max_area_px: int =250) -> pd.DataFrame:\n",
    "    \"\"\" \n",
    "    Filters a dataframe for detections with areas inside the range (min_area, max_area).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pd.DataFrame\n",
    "        Input dataframe.\n",
    "    min_area_px, max_area_px: int\n",
    "        Minimum/maximum area in pixels.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Filtered data frame.\n",
    "    \"\"\"\n",
    "    \n",
    "    filtered_df = df[(df[\"area_px\"] >= min_area_px) & (df[\"area_px\"] <= max_area_px)].reset_index(drop = True)\n",
    "    print(f\"Before area filter: {len(df)}\")\n",
    "    print(f\"After area filter: {len(filtered_df)}\")\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mask(sequence: MapSeq, frame: int, bright_pct: float = 99, dilation: int = 3, min_area: int = 150) -> np.ndarray:\n",
    "    \"\"\" \n",
    "    Builds a boolean mask of the brightest X% of pixels in a frame.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    sequence: sunpy.map.MapSequence\n",
    "        Input map sequence. \n",
    "    frame: int\n",
    "        Frame to be masked.\n",
    "    bright_pct: float, default 99\n",
    "        Percentage above which pixels should be masked out.\n",
    "    dilation: int, default 3\n",
    "        Expands mask slightly for smoother edges.\n",
    "    min_area: int, default 150\n",
    "        Minimum area (in pixels) of a detected patch to be added to the mask.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        n-dimensional array of boolean values (True = masked out).\n",
    "    \"\"\"\n",
    "    m = sequence[frame]\n",
    "    data = m.data.copy()\n",
    "    \n",
    "    threshold = np.percentile(data, bright_pct)\n",
    "    bright_mask = data > threshold\n",
    "    \n",
    "    labeled = label(bright_mask)\n",
    "    mask = np.zeros_like(bright_mask, dtype=bool)\n",
    "    \n",
    "    for region in regionprops(labeled):\n",
    "        if region.area >= min_area:\n",
    "            mask[labeled == region.label] = True\n",
    "    \n",
    "    if dilation > 0:\n",
    "        mask = binary_dilation(mask, disk(int(round(dilation))))\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def build_masks(sequence: MapSeq, bright_pct: float = 99, dilation: int = 3, min_area: int = 150) -> List[np.ndarray]:\n",
    "    \"\"\" \n",
    "    Builds masks for an entire sequence and stores them in a list.\n",
    "    \"\"\"\n",
    "    return [build_mask(sequence, frame, bright_pct, dilation, min_area) for frame in range(len(sequence))]\n",
    "\n",
    "def apply_masks(df: pd.DataFrame, masks: List[np.ndarray]) -> pd.DataFrame:\n",
    "    \"\"\" \n",
    "    Applies a list of masks to a dataframe, removing detections inside masked regions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pd.DataFrame\n",
    "        Input data frame.\n",
    "    masks: List[np.ndarray]\n",
    "        List of boolean n-dimensional arrays.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Filtered data frame.\n",
    "    \"\"\"\n",
    "\n",
    "    if \"frame\" not in df.columns:\n",
    "        raise ValueError(\"df must have a 'frame' column\")\n",
    "    \n",
    "    df = df.copy()\n",
    "    masked_out = np.zeros(len(df), dtype=bool)\n",
    "    \n",
    "    for frame, mask in enumerate(masks):\n",
    "        sub_df = df[df[\"frame\"] == frame]\n",
    "        if len(sub_df) == 0:\n",
    "            continue\n",
    "            \n",
    "        height, width = mask.shape\n",
    "        y = sub_df[\"y\"].round().astype(int)\n",
    "        x = sub_df[\"x\"].round().astype(int)\n",
    "        \n",
    "        in_bounds = (x >= 0) & (x < width) & (y >= 0) & (y < height)\n",
    "        valid_y = y[in_bounds]\n",
    "        valid_x = x[in_bounds]\n",
    "        \n",
    "        masked_out[sub_df.index[in_bounds]] = mask[valid_y, valid_x]\n",
    "    \n",
    "    df[\"masked_out\"] = masked_out\n",
    "    masked_df = df[~df[\"masked_out\"]].drop(columns=[\"masked_out\"])\n",
    "    print(f\"Before mask: {len(df)}\")\n",
    "    print(f\"After mask: {len(masked_df)}\")\n",
    "    return masked_df\n",
    "\n",
    "# helper function to visualize mask\n",
    "def visualize_mask(sequence: MapSeq, frame: int, mask: np.ndarray) -> None:\n",
    "    \"\"\" \n",
    "    Displays a sample frame (left) and the masked out regions (right).\n",
    "    \"\"\"\n",
    "\n",
    "    m = sequence[frame]\n",
    "    data = m.data.copy()\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12,5), dpi = 150)\n",
    "\n",
    "    # original frame\n",
    "    ax[0].imshow(data, cmap = \"Grays_r\", origin = \"lower\")\n",
    "    ax[0].set_title(f\"Original Frame {frame}\")\n",
    "    ax[0].axis(\"off\")\n",
    "\n",
    "    # mask overlay\n",
    "    ax[1].imshow(data, cmap = \"Grays_r\", origin = \"lower\")\n",
    "    ax[1].imshow(mask, cmap = \"Reds\", alpha = 0.4, origin = \"lower\")\n",
    "    ax[1].set_title(f\"Masked Regions {frame}\")\n",
    "    ax[1].axis(\"off\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_detections(df: pd.DataFrame, radius: int) -> pd.DataFrame:\n",
    "    \"\"\" \n",
    "    Merges detections within radius into one detection for each frame using DBSCAN.\n",
    "\n",
    "    Parameters:\n",
    "    df: pd.DataFrame\n",
    "        Input data frame.\n",
    "    radius: int\n",
    "         Radius inside of which detections get counted as one event.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Filtered data frame.\n",
    "    \"\"\"\n",
    "    merged_rows = []\n",
    "\n",
    "    for frame in df.frame.unique():\n",
    "        d = df[df[\"frame\"] == frame].copy()\n",
    "\n",
    "        if len(d) == 0:\n",
    "            continue\n",
    "        if len(d) == 1:\n",
    "            p = d.iloc[0]\n",
    "            merged_rows.append(p)\n",
    "            continue\n",
    "\n",
    "        coords = d[[\"x\", \"y\"]].values\n",
    "\n",
    "        # cluster detections based on spatial proximity\n",
    "        clustering = DBSCAN(eps = radius, min_samples = 1).fit(coords)\n",
    "        d[\"cluster_id\"] = clustering.labels_\n",
    "\n",
    "        # merge detections withing each cluster\n",
    "        for _, group in d.groupby(\"cluster_id\"):\n",
    "            merged = {\n",
    "                \"frame\": frame,\n",
    "                \"x\": group[\"x\"].mean(),\n",
    "                \"y\": group[\"y\"].mean(), # choose center of cluster as coordinates\n",
    "                \"area_px\": group[\"area_px\"].sum(), # add areas of individual detections (assuming no overlap)\n",
    "                \"area_Mm2\": group[\"area_Mm2\"].sum(),\n",
    "                \"intensity\": group[\"intensity\"].max() # choose max intensity\n",
    "            }\n",
    "            \n",
    "            bboxes = np.array(list(group[\"bbox\"]))\n",
    "            merged[\"bbox\"] = (\n",
    "                bboxes[:,0].min(), # [:,0] means all rows, column 0, so bottom\n",
    "                bboxes[:,1].min(), # left\n",
    "                bboxes[:,2].max(), # top\n",
    "                bboxes[:,3].max(), # right\n",
    "            )\n",
    "\n",
    "            merged_rows.append(merged)\n",
    "\n",
    "    filtered_df = pd.DataFrame(merged_rows).reset_index(drop = True)\n",
    "    print(f\"Before merging: {len(df)}\")\n",
    "    print(f\"After merging: {len(filtered_df)}\")\n",
    "    print(f\"Removed: {len(df) - len(filtered_df)}\")\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_event_catalog(df: pd.DataFrame,\n",
    "    cadence_seconds: float,\n",
    "    spatial_eps: float = 5,\n",
    "    temporal_eps_frames: float = 3,\n",
    "    min_samples: int = 2,\n",
    "    min_lifetime_seconds: float = 10,\n",
    "    max_lifetime_seconds: Optional[float] = 500.0,\n",
    "    max_area_Mm2: float = 15.0,\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Build a catalog of solar campfires from per-frame detections using spatiotemporal DBSCAN clustering followed by lifetime filtering\n",
    "    to identify and characterize campfire events.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Per-frame detections with columns: frame, x, y, area_px, area_Mm2, intensity, bbox\n",
    "    spatial_eps : float\n",
    "        Spatial clustering radius for DBSCAN in pixels\n",
    "    temporal_eps_frames : float\n",
    "        How close in time two events must be to be part of the same cluster (maximum gap in frames)\n",
    "    min_samples : int\n",
    "        Minimum detections required to form a cluster\n",
    "    min_lifetime_seconds : float\n",
    "        Minimum event duration to keep\n",
    "    max_lifetime_seconds : float, optional\n",
    "        Maximum event duration (None = no upper limit)\n",
    "    cadence_seconds : float\n",
    "        Time between frames in seconds\n",
    "    max_area_Mm2 : float\n",
    "        Maximum total area to qualify as campfire\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    catalog_df : pd.DataFrame\n",
    "        Event-level catalog with one row per campfire (summary statistics)\n",
    "    detections_df : pd.DataFrame\n",
    "        Per-frame detections with columns: event_id, frame, x, y, bbox, area_Mm2, intensity\n",
    "        (for use with visualization functions like make_movie())\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Starting with {len(df)} per-frame detections\")\n",
    "\n",
    "    # 1. Spatiotemporal DBSCAN clustering\n",
    "    # Scale temporal dimension: temporal_scale_factor converts frames to \"pseudo-pixels\"\n",
    "    # so that temporal_eps_frames <=> spatial_eps distance\n",
    "    temporal_scale_factor = spatial_eps / temporal_eps_frames\n",
    "    \n",
    "    X = np.column_stack([\n",
    "        df[\"x\"].values,\n",
    "        df[\"y\"].values,\n",
    "        df[\"frame\"].values * temporal_scale_factor\n",
    "    ])\n",
    "\n",
    "    db = DBSCAN(\n",
    "        eps = spatial_eps,\n",
    "        min_samples = min_samples,\n",
    "        metric = \"euclidean\",\n",
    "        n_jobs = -1 # use all available CPU cores\n",
    "    ).fit(X)\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"cluster_id\"] = db.labels_\n",
    "\n",
    "    n_clusters = len(set(db.labels_)) - (1 if -1 in db.labels_ else 0)\n",
    "    n_noise = list(db.labels_).count(-1)\n",
    "    print(f\"DBSCAN --> {n_clusters} clusters + {n_noise} noise points\")\n",
    "\n",
    "    # 2. Compute cluster statistics for filtering\n",
    "    stats = df[df[\"cluster_id\"] >= 0].groupby(\"cluster_id\").agg(\n",
    "        frame_min=(\"frame\", \"min\"),\n",
    "        frame_max=(\"frame\", \"max\"),\n",
    "        n_det=(\"frame\", \"count\"),\n",
    "        total_area_Mm2=(\"area_Mm2\", \"sum\"),\n",
    "    )\n",
    "    \n",
    "    stats[\"lifetime_frames\"] = stats[\"frame_max\"] - stats[\"frame_min\"] + 1\n",
    "    stats[\"lifetime_seconds\"] = stats[\"lifetime_frames\"] * cadence_seconds\n",
    "\n",
    "    # 3. Filter by lifetime and area\n",
    "    min_frames = min_lifetime_seconds / cadence_seconds\n",
    "    max_frames = np.ceil(max_lifetime_seconds / cadence_seconds) if max_lifetime_seconds else np.inf\n",
    "    \n",
    "    good_ids = stats[\n",
    "        (stats[\"lifetime_frames\"] >= min_frames) &\n",
    "        (stats[\"lifetime_frames\"] <= max_frames) &\n",
    "        (stats[\"total_area_Mm2\"] <= max_area_Mm2)\n",
    "    ].index\n",
    "\n",
    "    df = df[df[\"cluster_id\"].isin(good_ids)].copy()\n",
    "    print(f\"After lifetime/area filter --> {len(good_ids)} events remain\")\n",
    "\n",
    "    # 4. Build two outputs: event catalog + per-frame detections\n",
    "    catalog = []\n",
    "    per_frame_detections = []\n",
    "\n",
    "    for new_id, (cluster_id, group) in enumerate(df.groupby(\"cluster_id\"), start=1):\n",
    "        group = group.sort_values(\"frame\")\n",
    "\n",
    "        # Temporal properties\n",
    "        frames = group[\"frame\"].values\n",
    "        start_f, end_f = frames.min(), frames.max()\n",
    "        lifetime_frames = end_f - start_f + 1\n",
    "        lifetime_s = lifetime_frames * cadence_seconds\n",
    "\n",
    "        # Spatial bounding box (covering entire event / cluster)\n",
    "        x_min, x_max = group[\"x\"].min(), group[\"x\"].max()\n",
    "        y_min, y_max = group[\"y\"].min(), group[\"y\"].max()\n",
    "        width_px = x_max - x_min + 1\n",
    "        height_px = y_max - y_min + 1\n",
    "\n",
    "        # Intensity and area statistics\n",
    "        peak_intensity = group[\"intensity\"].max()\n",
    "        mean_intensity = group[\"intensity\"].mean()\n",
    "        total_area_Mm2 = group[\"area_Mm2\"].sum()\n",
    "        mean_detection_area_Mm2 = group[\"area_Mm2\"].mean()\n",
    "\n",
    "        # Event-level catalog entry\n",
    "        catalog.append({\n",
    "            \"event_id\": int(new_id),\n",
    "            \"n_detections\": len(group),\n",
    "            \n",
    "            # Temporal\n",
    "            \"frame_start\": int(start_f),\n",
    "            \"frame_end\": int(end_f),\n",
    "            # total duration (including gaps)\n",
    "            \"total_lifetime_frames\": int(lifetime_frames),\n",
    "            \"total_lifetime_seconds\": float(lifetime_s),\n",
    "            \"active_frames\": len(group),\n",
    "            \"active_seconds\": len(group) * cadence_seconds,\n",
    "            \"duty_cycle\": float(len(group) / lifetime_frames) if lifetime_frames > 0 else 0.0,\n",
    "\n",
    "            # Spatial - centroid\n",
    "            \"x_centroid\": float(group[\"x\"].mean()),\n",
    "            \"y_centroid\": float(group[\"y\"].mean()),\n",
    "            \"x_std\": float(group[\"x\"].std(ddof=0) or 0.0),\n",
    "            \"y_std\": float(group[\"y\"].std(ddof=0) or 0.0),\n",
    "            \n",
    "            # Spatial - bounding box\n",
    "            \"bbox_x1\": float(x_min),\n",
    "            \"bbox_y1\": float(y_min),\n",
    "            \"bbox_x2\": float(x_max),\n",
    "            \"bbox_y2\": float(y_max),\n",
    "            \"bbox_width_px\": float(width_px),\n",
    "            \"bbox_height_px\": float(height_px),\n",
    "            \n",
    "            # Intensity\n",
    "            \"peak_intensity\": float(peak_intensity),\n",
    "            \"mean_intensity\": float(mean_intensity),\n",
    "            \n",
    "            # Area\n",
    "            \"total_area_Mm2\": float(total_area_Mm2),\n",
    "            \"mean_detection_area_Mm2\": float(mean_detection_area_Mm2),\n",
    "            \"total_area_km2\": float(total_area_Mm2 * 1_000_000),\n",
    "            \"mean_detection_area_km2\": float(mean_detection_area_Mm2 * 1_000_000),\n",
    "            \n",
    "            # Original cluster ID (for debugging)\n",
    "            \"original_cluster_id\": int(cluster_id)\n",
    "        })\n",
    "        \n",
    "        # Per-frame detections (for visualization)\n",
    "        for _, detection in group.iterrows():\n",
    "            per_frame_detections.append({\n",
    "                \"event_id\": int(new_id),\n",
    "                \"frame\": int(detection[\"frame\"]),\n",
    "                \"x\": float(detection[\"x\"]),\n",
    "                \"y\": float(detection[\"y\"]),\n",
    "                \"bbox\": detection[\"bbox\"],\n",
    "                \"area_Mm2\": float(detection[\"area_Mm2\"]),\n",
    "                \"intensity\": float(detection[\"intensity\"]),\n",
    "            })\n",
    "\n",
    "    catalog_df = pd.DataFrame(catalog)\n",
    "    catalog_df = catalog_df.sort_values(\"frame_start\").reset_index(drop=True)\n",
    "    \n",
    "    detections_df = pd.DataFrame(per_frame_detections)\n",
    "    detections_df = detections_df.sort_values([\"frame\", \"event_id\"]).reset_index(drop=True)\n",
    "\n",
    "    # 5. Summary statistics\n",
    "    print(f\"\\n{'-'*60}\")\n",
    "    print(f\"Final campfire catalog: {len(catalog_df)} events\")\n",
    "    if len(catalog_df) > 0:\n",
    "        print(f\"Total lifetime range: {catalog_df['total_lifetime_seconds'].min():.1f} - \"\n",
    "              f\"{catalog_df['total_lifetime_seconds'].max():.1f} s\")\n",
    "        print(f\"Mean lifetime: {catalog_df['total_lifetime_seconds'].mean():.1f} s\")\n",
    "    print(f\"Per-frame detections for visualization: {len(detections_df)}\")\n",
    "    print(f\"{'-'*60}\\n\")\n",
    "\n",
    "    return catalog_df, detections_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Playground\n",
    "First, load a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"eui_hrieuv_20200530\"\n",
    "sequence = load_dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "In the next cells, you can play around with these algorithms. They are separated so you can tune individual parameters without having to compute everything from scratch in each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 3.425\n",
    "df: pd.DataFrame[CampfireData] = sigma_threshold(sequence, sigma, per_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = build_masks(sequence, 97.5, dilation = 2, min_area = 150)\n",
    "df_masked = apply_masks(df, masks)\n",
    "visualize_mask(sequence, 25, masks[49])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merge_detections(df_masked, radius = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df, detections = build_event_catalog(merged_df,\n",
    "    spatial_eps=3.8,\n",
    "    temporal_eps_frames = 2,     \n",
    "    min_samples=2,\n",
    "    min_lifetime_seconds=5,\n",
    "    max_lifetime_seconds=500,\n",
    "    cadence_seconds=5.0,          \n",
    "    max_area_Mm2=15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_csv(final_df, \"59\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = 7\n",
    "showcase_detections(sequence, frame, detections, 10, 0.1, 99.9, 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Here, you can make a movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_movie(sequence, detections, \"new_pipeline_test_50\", fps = 7, vmin_pct=0.5, vmax_pct = 99.5, show_detections = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
